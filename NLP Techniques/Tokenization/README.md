  # Tokenization 

Tokenization consists of breaking up a text into smaller parts called tokens (which can be sentences or words) to make text easier to handle. 
There is sentence tokenization to split sentences within a text, and word tokenization to split words within a sentence

You can use NLTK, SpaCy and TextBlob to Convert Text into Words or Sentences.