{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Stemming & Lemmatization using NLTK.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMxuOGsQyZqhw/7QFYocamG"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HAN3Swa6Ss1W","colab_type":"text"},"source":["# Stemming & Lemmatization using NLTK"]},{"cell_type":"markdown","metadata":{"id":"SW0Q0GBZ1A2S","colab_type":"text"},"source":["### Stemming"]},{"cell_type":"code","metadata":{"id":"P5uvxv1DSNuA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1598878190367,"user_tz":-60,"elapsed":1178,"user":{"displayName":"hamza ait-abbou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0cr-hVrG6gjAfh6Wk2ULdW3sSkpEl7X1Nq_iDeA=s64","userId":"06639353548098547981"}},"outputId":"3d809760-1b7e-4308-e194-cb9b7a2c0af7"},"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.stem import PorterStemmer\n","from nltk.stem import LancasterStemmer"],"execution_count":22,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4ozYEMBmv2Tt","colab_type":"text"},"source":["###### With PorterStemmer "]},{"cell_type":"code","metadata":{"id":"XeEfWcE7S1Ct","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598878191129,"user_tz":-60,"elapsed":1927,"user":{"displayName":"hamza ait-abbou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0cr-hVrG6gjAfh6Wk2ULdW3sSkpEl7X1Nq_iDeA=s64","userId":"06639353548098547981"}},"outputId":"5aa21ea1-3788-44da-efd4-a4c2af8517a5"},"source":["# create an instance of Porter Stemmer \n","porter_stemmer = PorterStemmer()\n","porter_stemmer.stem('writing')\n"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'write'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"M6QuALfxvvH_","colab_type":"text"},"source":["###### With LancasterStemmer "]},{"cell_type":"code","metadata":{"id":"L-oi-dKLwDA-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598878191132,"user_tz":-60,"elapsed":1919,"user":{"displayName":"hamza ait-abbou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0cr-hVrG6gjAfh6Wk2ULdW3sSkpEl7X1Nq_iDeA=s64","userId":"06639353548098547981"}},"outputId":"afe52294-89bb-4332-917c-5055d9c440ea"},"source":["Lanc_stemmer = LancasterStemmer()\n","Lanc_stemmer.stem('eats')"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'eat'"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"b5c9wnpaw3po","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":150},"executionInfo":{"status":"ok","timestamp":1598878191134,"user_tz":-60,"elapsed":1910,"user":{"displayName":"hamza ait-abbou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0cr-hVrG6gjAfh6Wk2ULdW3sSkpEl7X1Nq_iDeA=s64","userId":"06639353548098547981"}},"outputId":"895cfffa-4a20-424c-8963-4cb257679da3"},"source":["#A list of words to be stemmed\n","word_list = [\"troubling\", \"cats\", \"writing\", \"eating\",\"stabil\",\"destabilize\",\"waitting\"]\n","print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))\n","for word in word_list:\n","    print(\"{0:20}{1:20}{2:20}\".format(word,porter_stemmer.stem(word),Lanc_stemmer.stem(word)))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Word                Porter Stemmer      lancaster Stemmer   \n","troubling           troubl              troubl              \n","cats                cat                 cat                 \n","writing             write               writ                \n","eating              eat                 eat                 \n","stabil              stabil              stabl               \n","destabilize         destabil            dest                \n","waitting            wait                wait                \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jQerJUpq1L0S","colab_type":"text"},"source":["## Lemmatization"]},{"cell_type":"code","metadata":{"id":"1jAlNYIx1aE6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598878191134,"user_tz":-60,"elapsed":1898,"user":{"displayName":"hamza ait-abbou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0cr-hVrG6gjAfh6Wk2ULdW3sSkpEl7X1Nq_iDeA=s64","userId":"06639353548098547981"}},"outputId":"42a7c136-346c-4b4b-96ca-c96e81d5b06c"},"source":["from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","lemmatizer.lemmatize('books')"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'book'"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"_kV5Nk_T1lhq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":167},"executionInfo":{"status":"ok","timestamp":1598878191135,"user_tz":-60,"elapsed":1886,"user":{"displayName":"hamza ait-abbou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0cr-hVrG6gjAfh6Wk2ULdW3sSkpEl7X1Nq_iDeA=s64","userId":"06639353548098547981"}},"outputId":"4a0a7ec1-55ab-4df6-8621-91b276e5a69d"},"source":["sentence = \"He was running and eating at same time\"\n","\n","sentence_words = nltk.word_tokenize(sentence)\n","print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n","\n","#You need to provide the context in which you want to lemmatize that is the parts-of-speech (POS).\n","#This is done by giving the value for pos parameter in wordnet_lemmatizer.lemmatize.\n","\n","for word in sentence_words:\n","    print (\"{0:20}{1:20}\".format(word,lemmatizer.lemmatize(word, pos=\"v\")))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Word                Lemma               \n","He                  He                  \n","was                 be                  \n","running             run                 \n","and                 and                 \n","eating              eat                 \n","at                  at                  \n","same                same                \n","time                time                \n"],"name":"stdout"}]}]}